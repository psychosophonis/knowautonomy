## 1.

I enjoy hacking ideas, machines, code in order to explore what they might do. That is what I do and have always done. It took me a long time to work out that what defined and unified that interest and gave it the sense of a sort of...disicpline... was the notion of abstraction. (there is another paper here about the loss of new media as a discipline to the bad abstraction of digital media)

To that end I'm interested in exploring novel 'abstractions'in knowledge production much more than I am in __academic publishing__ -per se. I want to talk about how for ten years i worked voluntarily in academic publishing in spite of that - a kind of diversion of labour and energy away from an intent to experiment.

In fact my interest in Fibreculture as a group was intially as a place/group/platform that would support such rethinkings and experimentation - a group fundamentally concerned with thinking through the potentialities of new media ....and it was... so I also want to talk about how we _all_ spent the last ten years servicing and contributing to an academic journal in spite of that and not just an academic journal - but in extension,the university, the institution as a corporation that runs largely on a surplus of voluntary labour.

To put it another way..
  
I wonder if while Fibreculture's intent in exploring online publishing, open access and open source  -an attempt to 'occupy the academic journal'- actually ended up _occupying_ Fibreculture more generally - and in that case whether or not the journal and the journal article were relatively poor abstractions for intellectual expression and academic community. 

In extension of that point I want to ask whether the notion of 'occupying' anything is ever a great political abstraction for a revolutionary politics. We shouldn't have occupied the journal, we should have refactored academic writing, experimented with novel abstractions. There is something interesting here regarding what Ned refered to yesterday as an _autonomy of politics_ as opposed to a _political autonomy_ and the way we think through the political potential of technology and information architecture... that bigger question motivates what follows...(here I'm thinking of Tim Berners-Lee SOLID;  decentralisation requires a different logic of abstraction and construction not just a new architecture)

I should also acknowledge that there was another project in which I spent considerable amount of time thinking through and writing about cognition, cognitive ecologies, the relationship between mind and media, and the position of technology with regard to our ecology of thinking/feeling - with the help of Andrew.

Without restating the whole thing I was and continue to be fascinated on the one hand by Brian Massumi's positioning of affect as central to cognition - perception as cognition - cognition as largely _autonomic_ as opposed to _autonomous_  and on the other hand Stielger's Technics and Time which begins with _'technics apprehended as the horizon of all possibilty to come and all possibilty of a future.'_ 

Much of this came out of a concern for how we might best build what Stiegler called 'technologies of mind' and which I like to think as a 'spirited technics'. To put it as simply straightforwardly as possible - I'm interested in how we are always thinking with and through technics (technique/technology). So the interesting question (for me) is  not so much a concern for outscourcing of our cognition to machines - but how we are always doing so, have always done so - and how might we do it better or differently. 

I think there is a beguiling play between words autonomy and autonomic here and in evidence between the two thinkers I mentioned and in Ned's *autonomy of politics*. I wonder if an autonomy of politics might depend on careful attention to the autonomic continuities that begin with an intial abstraction and the way that abstraction modulates our interaction with a particular machine/algorithm/technique/technology.

I'm positing an abstraction as a kind of proto technics - forming and framing a horizon of technical possibility...

----------------
## 2

So in dialogue with the workshop's framing statement while I'm not so concerened with the outsourcing of cognition (we have always outsourced cognition, it is a function of how we think). I am more worried about the way machines outsource their affect to us and the way that can result in a kind of *feral continuity*. The kind of 'artificial' that concerns me most is a techno-bureacratic artificiality-  an automation of relations that (amongst other things) disavows care. That might include a lack of care for each other, for the medium itself, for intellectual expression ,but also more generally a culture of futures or futurity.

The most worriesome of 'artificial intelligence' or 'autonomous systems' are perhaps those of the bureaucracy and policy in which feral abstractions have become oddly infrastructural - 'oddly' because they remain visible, we'd like to replace them or update them, but they sustain themselves via their relentless demands for service and debt calling, and in doing suck the energy out of any potential for addressing or redressing the abstraction that provides the basis for their continuity. 

I've seen these feral continuities in university learning and teaching, in our high schools, in the health system (most tragically). I've even seen it as my once amateurish sport became professionalised, and of course in academic systems of knowledge production. The latter is my principal concern here but I'll use these other instances. 

-----------------

## 3

When I started with FCJ I was motivated by the thought that my strange blend of interests in tech and theory might find an outlet there. The mailing list, with which Fibreculture had begun and which had initally been a means of coalescing and organising for a dispersed community of antidisicplinary academics in a nascent field, was inspiring but was nearing the end of its 'life'. Mailing lists were/are actually great vehicles for community and intellectual expression. The good thing about them is that online communities (which are too fragile to be coopted), intellectual expression, and mailing lists don't make great abstractions for anything else (esteem, prestige for example) and so mailing lists thankfully die a natural timely death once they cease to serve as the basis for those things they were deplyed to support (community or intellectual expression/dialogue). 

This is a great and misunderstood thing. We should let things die. If we dont let our abstractions live and die on their own terms we infect them with franken-affects and create zombie continuities. This should provide a note for the workshop statement's 'horizon of doom', 'futurity without purpose' for 'the knowledge generated out of the academy' and fear of the journal article's absolesence -  my advice is to embrace the 'horizon of doom', embrace 'purposelessness', celebrate the journal article's 'obsolescence'. 

The demand to refactor comes from programming. Its usually the case when writing a program that at some point writng the code becomes laborious - a point at which you start fighting againstthe abstraction from which you began and upon which all subsequent code is based. The desire is to keep pushing the abstraction - bending it to your will. Eventually you tend to cometo a point when you understand there was a better way - a better abstraction from which to begin (or there HAD to be) - and to move forward you must refactor - start again with a different abstraction. Note that the problem is rarely the code itself- its not a technical problem and therefore doesn't have a technical solution - its the _idea_ that structures the code- thats shapes your subsequent interaction, or possible interactions with it.

## Notes on Feral Abstractions : Frankenmonsters in Education.

So as my bio states I'm apparently here under the guise of Polygon Door -a private creative tech lab I set up with another precarious university worker to explore the possibilty of forging an academic life outside of and away from the rolling casual 'contracts' of our precarious university existence. 

Under that guise I've spent the last year or so playing/designing/programming and teaching with programmable drawing machines - robots that draw - an open source riff on the old Turtle Bot idea originating with Seymour Papert but which had largely disappeared in contemporary learning and teaching. We developed the robot following a series of workshops where students developed and executed there own ideas on the Arduino microcontoller. Those workshops were a lot of fun but the output tended to be 'a game', and alarm, a sensor - that is buttotn and sensors seem to write themsleves into executable projects according to there affordances. Learning and teaching technical skills didn't result in creative agency (of course). We tried a number of variations including the use of narrative and aesthetics. We found aesthetics as an ideal vehicle for routing around an instrumental approach to creative technology.

Once the robot was built we wrote an api, and designed a pedagogy, for exploring creativity as a process of experimentation and observation. While the robot appeals - because _robot_ - the power of the device is that it routes around the notion that knowledge production, creative thinking, aesthetic invention - occurs in the head - as Papert has apparently written (although I can't source the citation immediately) - this is an 'object to think with'. It has been a lot of fun watching students learn the power of an algorithm to realise and extend novelty, to explore creative thinking and, yes innovation, as based in action and observation. Students (a parents/teachers) think they students are learning 'robotics' but what they actually learn is to think creatively, to learn to learn, by acting and observing and acting again. At some point a local high school took an interest and we 'pivoted' to that opportunity because some advisor told us thats what tech start-ups do (another bad abstraction for another day). Teachers love our little machine because students learn with it but Principals love it cause it ticks the STEM and Digital Curriculum box. The kits sell themselves but at some point I realised I am not really interested in selling tech to schools. It doesn't work - in spite of the robots demonstrated value and success. Once in the schools the robots tend to sit on shelves in 'maker spaces' equipped with mostly unused 3D printers. The robots serve a weird kind of purpose. They service a feral abstraction which cares nothing for their potential value as mechanism of knowledge production or for learning and teaching. They tend not to fit into a packed disciplinary curriculum in which outcomes are carefully stipuated monitored and ticked off. There is no time for open discovery - except when spare time is carved out as an exception. The best learning happens outside of class in spaces and times carved out of daily rigmarole by champion teachers. But even those champions are eventually forced back to class. Design and art teachers don't have time to engage with the complexities of code. Art spaces aren't fitted with computers. Computer spaces dont have space for electronics or drawing. Design and tech spaces are hampered by limited face time and a lack of technical expertise and interdsciplinary persepctive. Maths is purely framed as exam skills preparation.

Part of the issue is that technology alone is a bad abstraction for solving problems in learning and teaching (LMS's anyone?) and our problems in learning and teaching are tied to a monsterous machinic hybrid of policy, architecture, infrastructure and affect that has its own feral or perhaps zombie continuity. Technology alone can't refactor the bad abstractions at the heart and continuity of our education system - what is required is a refactoring of the abstractions of what it means to learn - and this would require us to begin again - to experiment with new abstractions. How the hell is that possible in the face of such a monstorous and multifacted continuity - under the demands on teachers to audit students, schools to audit teachers, and so on, and so on. 

The same intervention is required in the realm of academic knowledge prodcution - I'm sure there are one or two academics that will empathise with my robots. The problem is not technical - it's zombie infrastructural, 

## Notes on Feral Abstractions 2 : It's the abstraction stupid.

I also teach media art at UOW. One of the things I do there is that  I use aesthetics and code to teach _abstraction_. It tooks me a long time to understand that this is what united my love of theory and making as 'new' media. I know its an unpopular term, given away to 'digital' - a dumb concession that saw us lose our nascent disicpline before it had begun to develop... but that is another story - digital as a mistaken abstraction of new media.

Good programming is all about abstraction. Thats is its core activity. It is not principally about technical skills. Find a good abstraction and a program will write itself - teach a programmer abstraction and they will learn to code themselves. When we teach programming in media arts at UOW or at Polygon Door we immerse students in a study of an aesthetic - Perhaps Manfred Mohr, or Bridget Riley, Frider Nake - some computational, some simply abstreact modermism. In doing so we shift the emphasis away from technical skills to the abstraction of an aesthetic. In pursuit of an aesthetic Student's realise and are immersed in its complexity. Sometimes they realise that they need to refactor their program because the aesthetic wasn't about circles (for instance) after all - the aesthetic drives the programming the programming immerses the student in an aesthetic. If the program becomes hard to write - its probably a bad abstraction and its time to refactor  - to rewrite the program starting with a different set of assumptions...a different abstraction. This approach successfully shifts the emphasis away from technical skill acquisition and technology more generally. Learning programming as skills acquisition is a technqiue based on a bad abstraction- that programming is about learning a language, about syntax. It also means my students occasionally produce interesting art. Their art is interesting because for the most part it avoids looking like yet another creative coding processing sketch. Creative coding sketches in the wider tend to look kind of similar. Their aesthetic is driven by what Processing's abstractions like to do when they succesfully outsource their affect to humans - produce lots of processing sketches. Same goes for any technical architecture. 90% of sound art sounds like PD/Max. 90% of presentations are a list of points until some tech person goes- wait a minute there must be a technical solution to that and then 50% of those 90% and up swirling incohate, motion sickness inducing, presy presentations.

## Notes on Feral Abstractions 3:  Livelihood as Abstraction Part 1 - Clean Trails.

One of my Life's obsessions is endurance trail running. My sport was until recently a quaint backwater of amatuerism. No-one was making any money - people actually did it 'for the running'. There was a spiritual aspect to the pursuit that was almost anti-professional. That has changed, more people entered the sport, a market grew, a social media presence grew, events were streamed, more people entered the sport, athletes got sponsored, events became profitable, events got prize money, athletes have started to eek out a _livelihood_. 

All of a sudden drugs are a problem in trail running where before the notion of taking drug to complete or compete in a trail run would have been absurd - counter to the reason for doing it. A feral abstraction has taken hold. For a set of elite runners, trail running is now only secondarily about running. Its about livelihood. It seems that running clean and independently is a bad abstraction for livlihood, for genrating a large social media presence. It needed refactoring - so now trail running is an industry and it is no longer just about the running.This is good for the sport apparently- the professionalism that is. Drugs are always bad - the problem is always the Dirty Runner... not the bad abstraction that sees performance enhancement as the right abstraction for generating a livlihood in a realm in which competing means training full-time. It has now suddenly begun to dawn on us all.. we got it round the wrong way...running isn't meant to be the abstraction for industry and it turns out that industry is a really shitty abstraction for clean running- but the Brumby has bolted...the feral abstraction is loose. What I want to think about here is not the problem of drugs in sport but he problem of a feral abstraction that sees the simple joy of running abstracted by the demands of professionalisation, running as a terrible abstraction of livelihood, professionalism as a terrible abstraction of running. I want to gesture toward a lost amateurism where a measure of amatuerism is a means of auditing the culture for feral abstractions taken hold. We could make the same argument for music, art and of course writing, thinking.  

## 4

So.. Journals.

The workshops framing statement says that 'for years academics have submitted to the poltical economy of the publishig industries' for 'esteem, prestige, job security (?), an outlet for intellectual expression, a basis for research money and some sense of community. The first three of these, esteem, prestige, and job security? are great abstractions of human affect in the service of sustaining a publishing industry. Its the right abstraction for the publishing industry its works well to sustain it...but its makes a great example of the kind of the artificial- intelligence that concerns me - that techno-bureacratic artificiality-  an automation of relations that (amongst other things) disavows care that, as I said, might include a lack of care for each other, for the medium itself, for intellectual expression, but also more generally for a culture of futures or futurity. In the poltical economy of the publishing industry we saw the the latter two abstractions (community and intellectual expression) dumped because it turns out that providing an outlet for intellectual expression and commmunity are not great abstractions of affect in the service of an industry and institution. 

But we didn't want to work in the sustain of an industry (or institution) did we? - to eek out a 'relevance' within it - as it was positied yeaterday... we wanted *knowledge production*. Commmunity and Intellectual and expression/writing - and the bodies that produce it -weren't meant to be abstractions in the sustain of an industry -  the publishing industry was meant to be an abstraction for them.  Its time we audited that abstraction...if writing is an abstraction for *intellectual expression* and *community* (as the workshops framing tsaement asserts) how might we refactor our practices of knowledge production in support of that. 

Perhaps then we can invert the concern for machines that 'think better than us'; how might we build abstractions that allow us to think better with machines, and to build machines that allow us to think better - that is non-autonomously - acknowledging the propensity for our autonomic entrainment according to the potential of a given abstraction and the potenital it provides for the outsourcing of our affective drive in the service of the machine. How might we build machines/policies/architectures/infrastructures that employ affect in a manner that allows us to exploit what the machine allows *us* to do better - to extend cognition (thinking-feeling) beyond the habitual service of our present abstractions. 

## 5

So FCJ...

I took over the journal as the previous manager Lisa Gye couldn't face having to refactor - from manually marking up html to the adoption of a content management system. The great advance of  Web2.0 was apparently the realisation that we should seperate form from content - and indeed the possibilty of coding endless web pages by hand seemed to back that up. In hindsight I wonder if the values of that separation were overegged - something shifted at that point. When form and content were intertwined it meant you had to always consider both together and form could well follow content. You were encouraged back to look at the abstraction again (is this a traditional journal article?) - potentially refactor form specifically for a paper. It allowed you the agility to support novel experiments in knowldge production and manipulate form in its service. After web2.0 content increasingly followed form not the other way round. Of course it was not sustainable to run a journal otherwise... but Fibreculture  was born with this kind of question in mind.. once the form was set The Journal became a container for writing. The Journal abstraction was thus well embedded... automatic..  

I chose WP as architectures and went  because its seperation of form from content was based on a good simple abstraction - the power of that abstraction (site as journal as a series of posts)is the secret to wordpress continued dominance online (26% of the web in 2016). The simplest abstraction is almost always the right abstraction. The more we encode assumptions as elaborate abstractions of process and form the less agile your abstraction is - and the more likely at some point you will be forced to refactor the entire thing - an important note for when we refactor academic writing. Wordpress hasn't required refactoring in 15 years... its remarkable really.

When this involves a manipulation and interwining of code and content (as html did - and which required a massive effort to extract the legacy content) the more likely your are to be caught within that abstraction - your only choice is to serve it because the work invovled in moving it would be vast or the content itself would need refiguring. WP's simple, agile, abstraction would ostensibly allow us to refactor at any point - meaning we aren't (as) subject to the franken-affect platform bias - and we could actively experiment with novel abstractions of fibrecultural content. We can still abstract the whole journal as a json file - in fact you could do it today...because its licensced 'cc-by' anyone can ... (another note to the fear of data expropriation expressed in the framing statement - i don't think you can have your commons and dictate its terms..). The fact is - that we never really did this because we were too busy serving the journal as an abstraction in service and in perpetuation of the poltical economy of academic publishing.

I still think wordpress was a good abtraction for an academic journal. It needed some tweaking and perhaps an adherence to the form of a traditional journal meant I built complexity on top of WP's lovely simple abstraction that made it more difficult for others to work on the mundane technical stuff that needed to be done. The real mistake was that the academic journal was a shitty abstraction for a system of networked knowledge production, for intellectual expression, and community. This is the crux of this diatribe about feral abstraction. 

One of the other things that happened was that increasingly the development of infrastructures around open access publishing shifted from experimenting with novel forms and potentialities of openness - of an intellectual commons - to once of competing with (the corporate publishing industry and with other publications) and for the network effect in pursuing citations (a weird abstraction of reading). Time potentially spent between issues working on novel abstractions of knowledge production afforded by my lovely open source and content management system was spent building plugins to meet the demands of the next best greatest metadata standard, or the metadata standards of open access repositories, or of corporate or institutional indexers. 

If I denied that development citations would be sacrificed, the standing of the journal would slip, and so on and so on. While fundamentally opposed to audit culture we seemd completely indebted to its demands as an 'academic journal'. We were using the network - this agile, indeterminate, open beast to 'occupy' a shitty feral industrial abstraction which had already abstracted away intellectual expression and community (many society journals had long ago given over their intellectual capital to publishing houses) as the means to refactor and explore new abstractions for community and intellectual expression (as the fibreculture mailing list serendipitously did). In occupying that feral abstraction we've been pushing shit up hill trying to reaasert the journal as a useful abstraction for intellectual expression and community.

This led to platform bias. Increasingly it seemed the Open Journal System (OJS) made all of that network effect management stuff really easy. The demand to move to it was and is still great. Having transitioned one other journal to it - I'd rather stab myself in the eye. OJS further embeds logics and hierarchies of traditional academic journal production deep in its terribly convoluted code base. While the WP abstraction begins with a user, a post, and maybe comments - OJS begins with articles, reviewers, editors, contributors, managing editors, administrators, readers, reviews, volumes etc etc... While OJS is open source, its source is completely lacking in agility or openness, its abraction is deeply embedded. This means that there is realistically and without much hacking around only one form of journal that can be produced with it, one form of journal article. Transitioning to OJS would would free FCJ from the demands of meeting those aformentioned metdata requirements, it would be good for citations. But... we would be thoroughly and further entrained with the 'political economies of the publishing industry' -  we'd have completely *occupied* the academic journal...it'll be great *for* the journal, for its standing, its esteem. It will ensure we have a 'futurity with purpose'....right?

For the past 3 years or so FCJ has felt like a beast that required serving and part of a machine - the academic publishing system -  that required endless servicing. We increasingly felt like the journal had become 'a publishing service' for time poor academics. Moreover sometimes it felt that as independent community publication we were for many a second or third option - this seemed more true following the arbitrary journal rankings circus took hold - a better example of the inanity of audit culture I am yet to see (dumber than naplan). I have feared impending issues reaching editorial completion just as I knew my fellow managing editors had feared the issues' delivery - and quite rightly - the work was enormous and increasing as the demands to publish meant writing had become secondary to publishing, publishing had become secondary to instituional and professional audit, moreover community had been suffocated out so finding reviewers who would deliver was tough, and worse still analytics showed that reading had been abstracted out completely (because you can't measure it). More people wanted to publish than wanted to read what was published. Of course many who succesfully published with us did so in dedication to the project itself- for these people the journal remained or was worth fighting for as an outlet of intellectual expression and/or community. The editorial and managerial weight of producing the journal however meant that it struggled to serve these people well in the face of other demands. 

We can't actually  know how any abstraction will play out - we have to play it, abstractions demand material research - but we can 'audit' that abstraction in experimentation and play (indeed we have a responsibility to do so) - check that its doing what we signed it up for and if its time to refactor. The journals is a bad abstraction for the things I wanted it for, those two trade-offs I deemed worthy of our submission to the abstractions of the 'political economy of the publishing industries' - as an 'outlet for intellectual expression' and 'a sense of community'. We'd already decided that the 'poltical economy of the publishing industries' has abstracted away these things and we attempted to occupy the journal as a result. _Occupying_ ended up in an inversion of its intent -we should have seen this coming - occupations rarely serve revolutions. 

So where might that refactoring begin? It seems to me that refactoring might go back to consider why we write - what is the _purpose_ of our intellectual expression, why do we need an _outlet_, why in writing do we need some sense of _community_ - what function does it serve?. Once of the dissapointing aspects of the Journal abstraction is the reality that a journal actually does seem to be the place academic thinking goes to die- Or at least it goes into deep hibernation waiting for a someone searching an index somehwere to temporarily revive in a moment of barely qualified extraction in the form of a citation. As far as I can see (and I watch the analytics in spite of myself) we are writing more and more, and reading less and less. How might we refactor writing in the service of encouraging reading and how might we allow reading to fold forward in continuity with writing so that the network becomes a space of agile multilogue - but wait - it already is that - the technology is there and is not the answer anyway , the answer is perhaps in supporting an ecology of experimentation in open 'minor' abstractions (to call on D&G's notion of the minor) perhaps this is a means to what Ned called a autonomy of politics.


_________ Stuff largley cut from or abreviated in talk

How might we begin to refactor the way we think with machines in a manner that serves intellectual expression and community in a way that affords rather than disregards care for each other,for the medium itself, but also more generally for the culture of futures or futurity. How would we refactor writing's techniques and the technologies in order to save ourselves from a future of 'purposelessness' a future where our intellectual expression is reduced to a means for sustaining a livlihood alone.

Where might we start with refactoring and rethinking writing as an activitity of collective and extended thought? When discussing the nvidia paper (part of yesterdays discussion - Liam presented a set of three papers one being about a neural net/machine intelligence project that could create a photorealistic  model/celebrity (given a set of celebrity faces)using a technique called a Generative Adverserial Network (GAN). The GAN is constituted of a 'generator' and a 'discriminator' - the generator learns what processes succeed in generating a succesful model given the discriminators feedback on output http://research.nvidia.com/publication/2017-10_Progressive-Growing-of (If only had such well dilineated creative processes). In discussion we noted that the output was super-normative... precisely because it is a difference that makes a difference when it comes aesthetic novelty. We all intuitively understand that aesthetics is in large part the function of an _intrigue_, a movement of thought, irreducible to description precisely because it is based on being in excess of the norm, even in excess of extra-aesthetic reduction. (Masssumi's discussion of Sinatra's eyes...'as too blue'). 

The _selection_ of a difference, of novelty as valued and valuable is where machine learning and machines inevitably fall short because they are never intrigued by novelty (as far as I have experienced - I'd love to hear otherwise). Machine confusion doesn't render as curious or curiosity - and beauty is always a thing _of_ curiosity (that is to sya beauty is always and first, curious). In fact programming curiosity might be a fascinating computational/mechatronic challenge (I have some ideas as to how this might proceed - robotic 'skin' - the instrumental incorporation of pain and its aniticpation as the basis for an extension of thought might be a place to start). The machine learning algorithm works well in gaming because we can stipulate the conditions for a 'win'.  This was what interested us in the second paper presented by Liam - the case of a machine learning algorithm capable of beating humans at the overwhelmingly complex board game 'go'. What was noted as remarkable was that the machine produced ways of winnning that had been previoulsy unthought. These were alien algorithmic  startegies such that produced a novel aesthetic  of the game in process. The architecture of the game produced something new when the machine was allowed to route around habit, culture and agency. In this route the game-alogithm complex produced an aesthetic intrigue that is in fact far more interesting than its potenital to 'win' according to defined terms. In recognisinig this aethetic intrigue we humans have shifted the goal posts... 'Nice' win isn't simply a win - its a win that exposes a novel aspect of the game itself. The machine intelligence is here is more than simply algorithm its a complex play of intrigue between human, game and algorithm combined, a machinic extension of the game/body potential to produce novelty in the porcess of its execution/play. Machine's are a powerful means for producing novelty, routing around habit and the tendency to simple amplification (of a previously defined win (which Ramachandran mistook as a defintion of intrigue rather than its shortcut/shaorthand) they are hopeless at realising when a particular novelty is interesting. The most interesting thing in the case of both papers was not that an algorithm could 'think better than us' but that it could produce novelty - aesthetic intrigue, a new dymamic of the game in process - that it could never 'select' for and we couldn't have imagined...we needed the autonomy of the machine to afford the realisation of a novel aesthteic or conceptual intrigue between body an world.

As someone put it nicely yesterday (to paraphase from memory) 'in the arts and humanities we dont know how to win - but we know it when we see it'. Another way of thinking that through might be to suggest that its the invention of the game, the realisation of what it means to 'win', that the human body is well equipped for. Unfortunately this means that machines of all kinds, including those that I mentioned that particularly worried me - the officious and bureaucratic - know well, and are improving everyday, at how best to incorporate us (the body) more effectively. Machines can learn to entrain and incorporate humans very effectively because the 'win' is simply defined as more clicks - the machine can effectively produce more 'win' without ever requiring an understanding of how such a 'win' feels. Perhaps there are ways to hack and invert this generative capacity to novel ends - or perhaps the ends are novel enough if they cycle back to potentialise thought. We must work with abstractions that serve our autonomic thinking-feeling - rather than with systems that exploit that thinking feeling in the service of their own feral continuity.








